Chapter 6: The Engine
The Engine
In the previous chapters, we defined the thesis, the stack, and the timeline. Now, we must discuss the engine. The primary mechanism for driving this revolution are Benchmarks, they are our Targeting System.
It is crucial to understand that benchmarks are not merely scoreboards. In the old model of AI, we used benchmarks to look backward and record who was winning. We treated them like a scoreboard.
In the new model, we build Targeting Systems to predict, direct, and implement a future. A Targeting System is not passive; it is an active guidance mechanism. When we make a measurement legible (clearly defined), adversarial (hard to cheat), and above all, payable (tied to a financial reward), human and machine cognition automatically routes itself to solve that challenge. Where the target is set, capital follows. And where capital follows, capabilities compound.
This dynamic creates the Abundance Flywheel, the central mechanism for industrializing discovery. It operates as a virtuous 5-step cycle:
Commitment: Pre-committed compute is aimed at a specific, hard problem.
Focus: Research and Development (R&D) efforts are intensely focused until that target "Clears" (meaning a team finally passes the rigorous threshold).
Collapse: This ‘clear’ triggers a "Domain Collapse," shifting the field from an artisanal craft to an industrial process.
Surplus: This industrialization generates massive economic "Surplus," value created because the cost of doing the task has plummeted.
Reinvestment: Finally, that surplus is reinvested into even more compute, which is then aimed at the next, harder target.
This chapter makes that flywheel concrete. It specifies exactly how to build the targeting systems that will industrialize progress rather than merely report on it.
From Leaderboards to Targeting Systems
The first era of AI "leaderboards" was a necessary prelude, but that era is over. Those early benchmarks were narrow, academic, and easily "saturated," with AIs eventually achieving a perfect score.
The next era belongs to Targeting Systems. These are not static tests; they are engines that are prospective, blinded, and anti-gaming by design. A true Targeting System acts like a living weapons system. Following are five attributes of such a system:
1. Outcome-Grounded Optimization: A Targeting System does not care about abstract statistics like "accuracy on a dataset." It optimizes for real-world value. For example, an education-focused Targeting System doesn't measure how well an AI answers a multiple-choice question. It measures "Learning Gain per Hour": did the human student actually learn faster? In healthcare, it measures "Risk-Adjusted Clinical Outcomes": did the patient actually get better without side effects?
2. Prospective and Blinded Testing: A Targeting System is prospective, meaning it tests models on events and population cohorts that did not exist when the model was trained. This prevents the AI from simply memorizing the past. A weather prediction model, for example, is not tested on last year's hurricanes (which it could memorize). It is tested on *next week's* weather, where the answer is currently unknown to everyone.
3. Adversarial and Anti-Gaming: A Targeting System is adversarial, funded with a "red-team budget": money set aside specifically to hire experts (or other AIs) to try to trick, break, or "game" the system. The system constantly injects hard cases and shifts the data distribution to ensure the model isn't just getting lucky.
4. Auditable and Equity-Constrained: It is auditable, requiring public Decision Records for AI Systems (DR-AIS) and "replication packs" so that any claim of success can be verified by a third party. Critically, it is equity-constrained. Fairness bands and subgroup floors are built directly into the win condition. For example, in the case of a medical AI that cures cancer in 99% of patients but fails for 100% of a specific minority group, the Targeting System would mark it as a failure. Fairness is not an afterthought; it is a prerequisite for victory.
5. Continuous Operation Finally, it is continuous. It allows for rolling submissions and automated scoring 24/7, rather than being an annual pageant or competition.
Alpha for Policymakers
Your job is to define the target and fund the escrow. That is it. If you find yourself writing requirements for *how* the AI should work (e.g., "it must use a transformer architecture"), you have become The Muddle. Stop it. Define the "what" (the outcome) and let the market invent the "how."
The Abundance Flywheel in Motion
The flywheel is the engine that converts "compute as a utility" into "abundance as a reality." Here is how the cycle works in practice.
Step 1: Compute as Working Capital. It begins by treating compute as a form of financial capital. An organization pre-commits a budget for training and inference into an escrow account. This isn't just a vague promise of funding; it is a line item that is locked and ready to be deployed against a specific target.
Step 2: Focusing Effort. This money creates a gravity well and the target becomes the public "API surface" between ambition and capital. Because the reward is clear and the test is fair, the entire world is invited to compete. This focuses all Target-Aligned R&D in one direction, preventing wasted effort on problems that don't matter.
Step 3: Domain Collapse. This intense focus leads to Domain Collapse. The moment the right target is "cleared" (solved), the problem tips. Latent capacity floods into the field. What was once a heroic, artisanal feat, like discovering a novel drug, writing a formal mathematical proof, or designing a new material, suddenly becomes a routine, automated service.
Step 4: Surplus Capture This industrialization unlocks enormous Surplus Capture. The unit cost for the service plummets, while the quality of the outcome improves. This opens up entirely new business models. In this model, we move from paying lawyers by the hour to using "Pay-Per-Outcome" contracts. We move from hoping for electricity reliability to enforcing "Reliability SLAs" (Service Level Agreements) where the provider pays *you* if the lights flicker. We move to "Guaranteed Learning-Gain Floors" where schools are paid only if students learn.
Step 5: Reinvestment and Safety. Finally, this new value is Reinvested. The money saved is poured back into funding more compute, collecting richer datasets, and building broader "action surfaces" (robots and APIs). This new capital is aimed at the next, harder target, and the flywheel spins faster.
Take note that this entire process only compounds if the guardrails are programmatic. Safety is not a separate step; it is a mechanical component of the engine. We must install automatic "downshift" mechanisms and kill-switches. If the system detects a regression in safety or equity (i.e., if the AI starts making biased decisions or dangerous errors), the flywheel's governor kicks in and slows the system down instantly. This ensures we don't just go fast; we go fast safely.
How to Build an Engine, Not a Scoreboard
There is a fundamental difference between measuring progress and creating it. A poorly designed target creates nothing but paperwork and bureaucracy. A well-designed one creates an engine of progress. To ensure we build the latter, the following three design principles are strict and non-negotiable.
Principle 1: Bind it to a Real-World Outcome. We must stop measuring "proxies," which are metrics that *look* like success but aren't. We must measure the actual result we want in the physical world.
In Healthcare: Do not measure "number of patients seen." Measure Time-to-Therapy (TTT) (how fast did they get treated?) and Risk-Adjusted Readmissions Avoided (did they stay healthy, or did they bounce back to the hospital?).
In Education: Do not measure "hours of class time." Measure Learning Gain per Hour (LG/H). Furthermore, verify it with retention floors that check if the student still knows the material 30, 60, and 180 days later.
In Infrastructure: Do not measure "uptime." Measure Reliability Minutes Avoided and Avoided-Loss Dollars per Megawatt. How much money did you save the economy by *not* crashing the grid?
Principle 2: Make it Prospective, Rolling, and Resistant to Gaming. If you test a student on last year's exam, they will memorize the answers. The same is true for AI. We must "freeze" a scoring harness that only admits future data.
The Method: Run the test weekly, not yearly. This prevents "teaching to the test."
Goodhart-Resistant Design: We must prevent the AI from optimizing one metric at the expense of others (e.g., being fast but dangerous). To do this, we use Multi-Objective Scoring that optimizes a "Pareto Frontier." This means the AI only wins if it improves accuracy *without* sacrificing safety, latency, equity, or cost.
Calibrated Abstention: We must reward the model's "right to remain silent." If an AI's uncertainty is high, it should get points for saying, "I don't know," rather than guessing.
Hidden Test Sets: The test data must be managed by independent third-party stewards and constantly shifted so no one can game the system.
Principle 3: Attach Automatic Payment and Publish the Artifacts. A target clear must be a contractual event, not a suggestion.
The Payment: When the target is hit, the system must automatically unlock the reward, whether that is compute credits, cash rebates, or outcome-based fees. There should be no human gatekeepers and no "RFP theater" (Request for Proposal delays).
The Price of Winning: In return for the money, the winner must pay with transparency. They must ship a "Replication Pack": the code, the evaluation scripts, the "ablations" (breakdowns of what parts worked), and the Decision Records for AI Systems (DR-AIS) that state exactly what changed and why.
Alpha for Builders
Before you write a single line of code for an agent, build its test harness first. Build the "Counterfactual Pack"—the complete set of difficult, adversarial cases that *should* force your agent to fail or abstain. Publish both the harness and the pack. You will earn trust, and you will move faster because you have defined what "correct" means before you even start building.
Case Patterns: How Targets Tip Domains
This is not a theoretical model or a wish list. We have already seen this pattern work in the real world. Here are four specific examples where a Targeting System tipped a domain from an art into a science.
1. AlphaFold (Structural Biology): This is the archetype example. The ingredients were simple:
A Clear Target: Predict the 3D structure of a protein from its amino acid sequence.
A Shared Corpus: The Protein Data Bank (massive training data).
A Public Competition: CASP (Critical Assessment of Structure Prediction). These conditions created a discontinuity. Once the target became credible, DeepMind poured scaled compute into the stack, and the domain collapsed. The release of the open artifact allowed the entire world to compound the win, accelerating biology globally.
2. Tutoring (Education): This will be one of the next domains to fall. Currently, schools buy software licenses. Soon, they will buy "Learning Gain per Hour." The market will re-align overnight. AI Copilots that provably beat the learning-gains per hour (LG/H) floor will be procured automatically. Those that drift or fail to teach will be automatically "downshifted" (removed). Public dashboards will create a tournament of ideas that pays the students first, not the vendors.
3. The Reliability Pattern (Power Grids): This pattern will solve our energy infrastructure. "Dispatcher Agents" (AI systems that manage power flow) will compete to reduce outage minutes.
The Test: Models will have to prove their resilience under adversarial weather (simulated hurricanes) and massive demand spikes (simulated heatwaves) inside the harness.
The Reward: Clearing the reliability target will earn the AI agent a "Capacity Contract" to manage a portion of the grid. Failure will trigger automatic throttles to prevent real-world blackouts.
4. The Time-to-Property ( TtP ) Pattern (Materials Science): This pattern will industrialize the laboratory. With the amount of time and compute (Time-to-Property) required to make the discovery becoming the North Star metric.
The Shift: Instead of measuring "how many papers you published," we measure "how many hours it took you to find a material with Property X" (e.g., a specific conductivity or strength).
The Mechanism: Robotic rigs with built-in MRV (Measurement, Reporting, Verification) will automatically upload results to the scoreboard. Agents that clear TtP targets on new chemistries will automatically unlock batches of lab time and compute credits to keep going.
Alpha for Auditors
Your job is to make the engine stronger, not just to watch it run. Fund "Red-Team Endowments." Pay public bounties to anyone who can demonstrate an exploit, such as a way to cheat the target or cause a failure, that would have cleared the target but failed in the real world. These "post-mortems" must be forced into the public replication packs, hardening the entire ecosystem against future errors.
The Institutions That Make the Engine Run
The Abundance Flywheel does not spin in a vacuum. It requires a new set of "primitives": the fundamental building blocks of the institutional infrastructure that supports the new economy. Just as the industrial economy needed banks, limited liability corporations, and property rights to function, the abundance economy relies on five specific structures we’ve described throughout this essay thus far.
1. Targeting Authorities: These are the public-private bodies responsible for defining the rules of the game. They define, host, and govern the Abundance Targets. Think of them as the modern equivalent of a standards body like NIST or ISO, ensuring the targets remain relevant and fair.
2. Data Trusts: We need legal and technical wrappers that turn raw data into safe fuel. A Data Trust is a system that holds high-quality data with consent. It uses code to enforce "privacy budgets" (limiting how much information can be extracted) and "revocation rights" (allowing a user to pull their data back). It transforms messy, risky data into a lawful asset with a clear lineage.
3. Action Networks: Intelligence needs a physical body to affect the world. Action Networks are shared facilities, such as robotic laboratories, microfactories, and clinical device hubs, accessible via API. They allow a "winner" of a Targeting System to instantly translate their digital solution into a physical reality, effectively giving a software agent hands and feet without requiring it to own a factory.
4. Compute Escrow: This is a new financial primitive. Instead of writing a check, funders place training credits or cash into a "Compute Escrow" account. This is a smart contract that programmatically releases funds *only* when a specific threshold is cleared. Crucially, it creates accountability; the system can "claw back" funds if the performance subsequently regresses, aligning financial incentives perfectly with sustained performance.
5. Outcome Procurement: Finally, we must overhaul government and corporate contracting. We are retiring the old model of paying for "deliverables" (reports, meetings, effort). In its place, we establish contracts that pay strictly for verified outcomes. If the pothole is fixed, the payment clears. If the student learns, the school is paid.
The New Economic Dashboard: We will know this system is working not by looking at traditional GDP, but by tracking a new set of economic indicators. The new "jobs report" will focus on metrics like RoCS (Return on Cognitive Spend), which measures the value created per dollar of compute. We will track the D2P24 (the percentage of designs that turn into verified parts in 24 hours) and the E2C Index (useful cognitive work per kilowatt-hour). We will monitor the CO₂e Ledger (the cost per ton of carbon durably removed), and the LG/H (Learning Gain per Hour). These numbers tell us if we are actually building abundance or just spinning our wheels.
Failure Modes and Programmatic Safety
This engine is powerful, but it has specific "failure modes" regarding ways it can break or be gamed. We must build programmatic safety measures to counter them effectively.
1. Countering "Spec Capture": One major risk is "Spec Capture," where the metric stops reflecting the true mission, similar to "teaching to the test" in schools. This happens when an AI optimizes for the score but ignores the real-world goal. We fix this by publishing explicit maps that link Purpose, Task, and Metric, and by rotating independent stewards. By constantly refreshing the people and the tests, we prevent the system from becoming stagnant or gamed.
2. Countering Data Leakage: Another risk is cheating via "Data Leakage," where a model performs well because it has memorized the answers from the test set. We fix this using "rolling, cryptographically-committed holdouts." This means the test questions are kept in a digital vault that the AI cannot see until the moment of the exam, ensuring that every pass is a genuine display of capability.
3. Countering Monoculture: A subtle but dangerous risk is "Monoculture," where everyone relies on the same single AI model. If that model has a bug, the entire system crashes. We fix this by mandating "multi-compiler and multi-toolchain rules" for safety-critical domains.
4. Countering Reliability Variance: Finally, we must prevent "Performance Drift," where a system optimizes for the "easy" majority while failing on edge cases or specific cohorts. In a solved world, high variance is a defect. We fix this by enforcing Universal Quality Floors. If a model improves the aggregate score but allows reliability to degrade for *any* specific segment of the population, it is rejected as unstable. We use "automatic throttling" to arrest the system the moment such variance appears, ensuring that abundance is delivered as a reliable standard, not a lottery.
Alpha for Investors & Philanthropists
Buy the primitives. The durable, compounding value in this new economy will not be found in owning any single AI model. Models are destined to be commoditized; they are the "trains" that will eventually all look the same. The real value lies in owning the "rails": the targeting platforms, the audit infrastructure, the data trusts, the action networks, and the compute escrow services. The trains will come and go, but the rails will determine where they can travel.
[← PreviousThe Mobilization](#ch5)
[Next →The Moonshots](#ch7)
07
Chapter 7
